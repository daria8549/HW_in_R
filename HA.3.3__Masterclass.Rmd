---
title: "HA.3.3__Masterclass"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# HA: Home Assignments

When submitting to Canvas, make sure to submit this .Rmd file with your solutions and not the knitted PDF, HTML or any other file. Note: In order to be able to complete the assignments, you may need to re-run the .Rmd codeblocks in the current week's notebook to have the variables required stored in your local environment.

## HA.3.3 (Masterclass - 1 point)

Your task now is to write a custom aggregation function which uses 3 separate aggregation methods (you can use 'no misery' or approval but not both). You are given complete freedom to choose your methods, although the resulting aggregation should make sense from a practical perspective for LastCentury.

```{r}
least_misery <- function(ratings) {
  sort(apply(ratings,2,function(x) {
    min(x,na.rm=T)
  }),decreasing=T)
}

borda <- function(ratings) {
  sort(apply(apply(ratings,1,function(x) {
    rank(x,na.last = 'keep')
  }),1,function(y) {
    sum(y,na.rm=T)
  }),decreasing = T)
}

ranked_approval <- function(ratings, alpha = 3) {
  sort(apply(ratings, 2, function(x) {
    sum(ifelse(x >= alpha, x, 0), na.rm = T)  # sum of ratings >= alpha, instead of sum of users
  }), decreasing = T)
}

custom_aggregation <- function(ratings, alpha = 3) {
  lm_result <- least_misery(ratings)   #[1-4]
  borda_result <- borda(ratings)       #[14-15]
  ra_result <- ranked_approval(ratings)#[3200-3268]

  normalize <- function(x) (x - min(x)) / (max(x) - min(x)) # normalizing result (0-1 scale)
  sort((normalize(lm_result * ra_result * borda_result)^(1/3)), decreasing = TRUE)
}

test_df <- read.csv("HA.3.n__dataset.csv")

head(custom_aggregation(test_df))
```


Explain in a couple of sentences what your aggregation method does and how it can be relevant for LastCentury.

```
Least Misery - ensures that no one is dissatisfied. (No misery makes a rating a bit more extreme)
Borda - focuses on overall popularity and consensus across the group
Ranked Approval - prioritize popular and well-regarded items, above a certain threshold (Average approval concentrated more on the number of ratings, not necessarily the quality of those ratings)

Combined geometrical mean reduces the impact of extreme outliers, which makes the final score more balanced.

```